---
title: Action Detection for Wildlife Monitoring with Camera Traps Based on Segmentation
  with Filtering of Tracklets (SWIFT) and Mask-Guided Action Recognition (MAROON)
type: pub
encoding: UTF-8

---
<h1>Publikasjon</h1>
<article id="csl-bib-container-GKB3TN8N" class="csl-bib-container">
  <div class="csl-bib-body"> <div class="csl-entry">Schindler, F., Steinhage, V., van Beeck Calkoen, S. T. S., &#38; Heurich, M. (2024). Action Detection for Wildlife Monitoring with Camera Traps Based on Segmentation with Filtering of Tracklets (SWIFT) and Mask-Guided Action Recognition (MAROON). <i>Applied Sciences</i>, <i>14</i>(2), 514. <a href="https://doi.org/10.3390/app14020514">https://doi.org/10.3390/app14020514</a></div> </div>
  <div class="csl-bib-buttons">
    <a href="#taxonomy-article-GKB3TN8N" alt="archive" class="csl-bib-button">Arkiv</a>
    <a href="https://app.cristin.no/results/show.jsf?id=2270413" alt="Cristin" class="csl-bib-button">Cristin</a>
    <a href="http://zotero.org/groups/5881554/items/GKB3TN8N" alt="Zotero" class="csl-bib-button">Zotero</a>
    <a href="#keywords-article-GKB3TN8N" alt="keywords" class="csl-bib-button">Emneord</a>
    <a href="#about-article-GKB3TN8N" alt="about_pub" class="csl-bib-button">Om</a>
    <a href="#sdg-article-GKB3TN8N" alt="sdg" class="csl-bib-button">Berekraftsmål</a>
    <a href="https://www.mdpi.com/2076-3417/14/2/514/pdf?version=1704619491" alt="Unpaywall" class="csl-bib-button">Unpaywall</a>
    <a href="https://www.mdpi.com/2076-3417/14/2/514/pdf?version=1704619491" alt="EZproxy" class="csl-bib-button">EZproxy</a>
  </div>
  <div id="csl-bib-meta-container-GKB3TN8N"></div>
</article>
<div id="csl-bib-meta-GKB3TN8N" class="csl-bib-meta">
  <article id="about-article-GKB3TN8N" class="about_pub-article">
    <h1>Om</h1>
    Schindler et al. utvikla ein ny metode for automatisk analyse av dyreatferd i naturen ved bruk av kamerafellevideoar. Tilnærminga deira, kalla SWIFT og MAROON, oppdagar dyr og gjenkjenner handlingane deira. SWIFT hjelper med å spore dyr i videoar, medan MAROON bruker detaljerte masker og eit trippel-strøms nettverk for å identifisere handlingar meir nøyaktig, sjølv når fleire dyr er til stades. Testa på videoar av hjort tatt både dag og natt, forbetra MAROON nøyaktigheita av handlingsgjenkjenning med 10 prosentpoeng samanlikna med andre metodar, og oppnådde 69,16% nøyaktigheit på eitt datasett. Dette systemet kan betydeleg redusere det manuelle arbeidet for økologar og gi konsistente, verdifulle innsikter i dyreatferd.
  </article>
  <article id="keywords-article-GKB3TN8N" class="keywords-article">
    <h1>Emneord</h1>
    Overvaking av dyreliv, Kamerafeller, Handlingsdeteksjon, Dyreatferd, SWIFT, MAROON, Handlingsgjenkjenning
  </article>
  <article id="abstract-article-GKB3TN8N" class="abstract-article">
    <h1>Samandrag</h1>
    Behavioral analysis of animals in the wild plays an important role for ecological research and conservation and has been mostly performed by researchers. We introduce an action detection approach that automates this process by detecting animals and performing action recognition on the detected animals in camera trap videos. Our action detection approach is based on SWIFT (segmentation with filtering of tracklets), which we have already shown to successfully detect and track animals in wildlife videos, and MAROON (mask-guided action recognition), an action recognition network that we are introducing here. The basic ideas of MAROON are the exploitation of the instance masks detected by SWIFT and a triple-stream network. The instance masks enable more accurate action recognition, especially if multiple animals appear in a video at the same time. The triple-stream approach extracts features for the motion and appearance of the animal. We evaluate the quality of our action recognition on two self-generated datasets, from an animal enclosure and from the wild. These datasets contain videos of red deer, fallow deer and roe deer, recorded both during the day and night. MAROON improves the action recognition accuracy compared to other state-of-the-art approaches by an average of 10 percentage points on all analyzed datasets and achieves an accuracy of 69.16% on the Rolandseck Daylight dataset, in which 11 different action classes occur. Our action detection system makes it possible todrasticallyreduce the manual work of ecologists and at the same time gain new insights through standardized results.
  </article>
  <article id="sdg-article-GKB3TN8N" class="sdg-article">
    <h1>Berekraftsmål</h1>
    <div class="sdg-container"><div id="sdg15" class="sdg">
        <img src="{{< params subfolder >}}images/sdg/sdg15_nn.png" class="image" alt="SDG 15">
        <div class="sdg-overlay">
          <a href="/nn/archive/?key=?sdg=15#archive" class="sdg-publication-count"><span>538</span> publikasjonar</a>
          <p><a href="https://fn.no/om-fn/fns-baerekraftsmaal/livet-paa-land?lang=nno-NO" class="sdg-read-more">Les meir</a></p>
        </div>
      </div></div>
  </article>
  <article id="taxonomy-article-GKB3TN8N" class="taxonomy-article">
    <h1>Arkiv</h1>
    <ul>
      <li>
        <a href="/nn/archive/?key=3DCRN523">Universitetet i Innlandet</a>
      </li>
      <li>
        <a href="/nn/archive/?key=T77LXH6D">Fakultet for anvendt økologi, landbruksfag og bioteknologi</a>
      </li>
      <li>
        <a href="/nn/archive/?key=7TRARPE3">Institutt for skog- og utmarksfag</a>
      </li>
      <li>
        <a href="/nn/archive/?key=A4XX8HDP">2024</a>
      </li>
      <li>
        <a href="/nn/archive/?key=2IXDX4YB">Mai</a>
      </li>
    </ul>
  </article>
</div>
