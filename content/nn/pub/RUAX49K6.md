---
title: Automated visitor and wildlife monitoring with camera traps and machine learning
type: pub
encoding: UTF-8

---
<h1>Publikasjon</h1>
<article id="csl-bib-container-RUAX49K6" class="csl-bib-container">
  <div class="csl-bib-body"> <div class="csl-entry">Mitterwallner, V., Peters, A., Edelhoff, H., Mathes, G., Nguyen, H., Peters, W., Heurich, M., &#38; Steinbauer, M. J. (2024). Automated visitor and wildlife monitoring with camera traps and machine learning. <i>Remote Sensing in Ecology and Conservation</i>, <i>10</i>(2), 236–247. <a href="https://doi.org/10.1002/rse2.367">https://doi.org/10.1002/rse2.367</a></div> </div>
  <div class="csl-bib-buttons">
    <a href="#taxonomy-article-RUAX49K6" alt="archive" class="csl-bib-button">Arkiv</a>
    <a href="https://app.cristin.no/results/show.jsf?id=2173736" alt="Cristin" class="csl-bib-button">Cristin</a>
    <a href="http://zotero.org/groups/5881554/items/RUAX49K6" alt="Zotero" class="csl-bib-button">Zotero</a>
    <a href="#keywords-article-RUAX49K6" alt="keywords" class="csl-bib-button">Emneord</a>
    <a href="#about-article-RUAX49K6" alt="about_pub" class="csl-bib-button">Om</a>
    <a href="#sdg-article-RUAX49K6" alt="sdg" class="csl-bib-button">Berekraftsmål</a>
    <a href="https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/rse2.367" alt="Unpaywall" class="csl-bib-button">Unpaywall</a>
    <a href="https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/rse2.367" alt="EZproxy" class="csl-bib-button">EZproxy</a>
  </div>
  <div id="csl-bib-meta-container-RUAX49K6"></div>
</article>
<div id="csl-bib-meta-RUAX49K6" class="csl-bib-meta">
  <article id="about-article-RUAX49K6" class="about_pub-article">
    <h1>Om</h1>
    Mitterwallner et al. gjennomførte ein studie ved bruk av kamerafeller og eit maskinlæringsverktøy kalla MegaDetector for å overvake menneske- og dyreaktivitetar i naturlege område. Dei testa verktøyet si evne til å identifisere og telle menneske, dyr og køyretøy i over 300,000 bilete frå ulike regionar. Verktøyet viste høg nøyaktigheit: 96% for dyr, 93.8% for menneske, og 99.3% for køyretøy. Det samsvarte også effektivt med manuelle klassifiseringar i langtidsstudier, og beviste si pålitelegheit for kontinuerleg overvaking. Denne teknologien akselererer databehandling og sikrar konsistente resultat, noko som gjer det nyttig for økologisk forsking medan det respekterer personvernreglar. Studien framhevar korleis teknologi kan hjelpe oss å betre forstå interaksjonar mellom menneske og dyreliv, som er viktig ettersom menneskelege aktivitetar i naturlege område aukar.
  </article>
  <article id="keywords-article-RUAX49K6" class="keywords-article">
    <h1>Emneord</h1>
    Kamerafeller, Maskinlæring, Objektgjenkjenning, Menneske-dyreinteraksjonar, Bildeklassifisering, Temporal analyse
  </article>
  <article id="abstract-article-RUAX49K6" class="abstract-article">
    <h1>Samandrag</h1>
    As human activities in natural areas increase, understanding human–wildlife interactions is crucial. Big data approaches, like large‐scale camera trap studies, are becoming more relevant for studying these interactions. In addition, open‐source object detection models are rapidly improving and have great potential to enhance the image processing of camera trap data from human and wildlife activities. In this study, we evaluate the performance of the open‐source object detection model MegaDetector in cross‐regional monitoring using camera traps. The performance at detecting and counting humans, animals and vehicles is evaluated by comparing the detection results with manual classifications of more than 300 000 camera trap images from three study regions. Moreover, we investigate structural patterns of misclassification and evaluate the results of the detection model for typical temporal analyses conducted in ecological research. Overall, the accuracy of the detection model was very high with 96.0% accuracy for animals, 93.8% for persons and 99.3% for vehicles. Results reveal systematic patterns in misclassifications that can be automatically identified and removed. In addition, we show that the detection model can be readily used to count people and animals on images with underestimating persons by −0.05, vehicles by −0.01 and animals by −0.01 counts per image. Most importantly, the temporal pattern in a long‐term time series of manually classified human and wildlife activities was highly correlated with classification results of the detection model (Pearson's r = 0.996, p  0.001) and diurnal kernel densities of activities were almost equivalent for manual and automated classification. The results thus prove the overall applicability of the detection model in the image classification process of cross‐regional camera trap studies without further manual intervention. Besides the great acceleration in processing speed, the model is also suitable for long‐term monitoring and allows reproducibility in scientific studies while complying with privacy regulations.
  </article>
  <article id="sdg-article-RUAX49K6" class="sdg-article">
    <h1>Berekraftsmål</h1>
    <div class="sdg-container"><div id="sdg15" class="sdg">
        <img src="{{< params subfolder >}}images/sdg/sdg15_nn.png" class="image" alt="SDG 15">
        <div class="sdg-overlay">
          <a href="{{< params subfolder >}}nn/archive/?sdg=15#archive" class="sdg-publication-count"><span>538</span> publikasjonar</a>
          <p><a href="https://fn.no/om-fn/fns-baerekraftsmaal/livet-paa-land?lang=nno-NO" class="sdg-read-more">Les meir</a></p>
        </div>
      </div></div>
  </article>
  <article id="taxonomy-article-RUAX49K6" class="taxonomy-article">
    <h1>Arkiv</h1>
    <ul>
      <li><a href="{{< params subfolder >}}nn/archive/?key=3DCRN523">Universitetet i Innlandet</a></li>
      <li><a href="{{< params subfolder >}}nn/archive/?key=T77LXH6D">Fakultet for anvendt økologi, landbruksfag og bioteknologi</a></li>
      <li><a href="{{< params subfolder >}}nn/archive/?key=7TRARPE3">Institutt for skog- og utmarksfag</a></li>
      <li><a href="{{< params subfolder >}}nn/archive/?key=WXLLSUEU">2023</a></li>
      <li><a href="{{< params subfolder >}}nn/archive/?key=AGMKHRCB">September</a></li>
    </ul>
  </article>
</div>
